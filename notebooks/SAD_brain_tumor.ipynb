{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daebcc3c",
   "metadata": {},
   "source": [
    "# Système d’Aide à la Décision (SAD) – Diagnostic de tumeurs cérébrales\n",
    "Module Machine Learning (ALIF83) – 2025–2026\n",
    "Yann Renvoisé, Aïssa Mehenni, LSI2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9028f24",
   "metadata": {},
   "source": [
    "## 0. Contexte et objectif\n",
    "- Différence classification vs aide à la décision\n",
    "- Objectifs du SAD (confiance, triage, actions, minimiser faux négatifs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dcfc51",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "- Imports\n",
    "- Seed\n",
    "- Paramètres globaux (paths, image size, batch size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc88e811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent  # notebooks/ -> Projet_SAD/\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "from src.preprocessing import get_default_config, list_images_by_class, compute_class_counts, load_image_cv2, normalize_0_1, make_sklearn_features\n",
    "from src.models import train_logistic_regression\n",
    "from src.calibration import calibrate_sklearn_classifier\n",
    "from src.decision_engine import DecisionThresholds, generer_recommandation\n",
    "from src.reporting import creer_rapport_decision\n",
    "\n",
    "cfg = get_default_config(PROJECT_ROOT)\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"Train dir:\", cfg.train_dir)\n",
    "print(\"Test dir:\", cfg.test_dir)\n",
    "print(\"Classes:\", cfg.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764a3bae",
   "metadata": {},
   "source": [
    "## 2. Données\n",
    "### 2.1 Chargement du dataset (Training/Testing)\n",
    "- Listing des classes\n",
    "- Comptage des images par classe\n",
    "### 2.2 Visualisation\n",
    "- Quelques exemples par classe\n",
    "### 2.3 Prétraitements\n",
    "- Redimensionnement\n",
    "- Normalisation\n",
    "- Augmentation (train uniquement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247276be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = list_images_by_class(cfg.train_dir, cfg.class_names)\n",
    "test_imgs  = list_images_by_class(cfg.test_dir, cfg.class_names)\n",
    "\n",
    "print(\"Train counts:\", compute_class_counts(train_imgs))\n",
    "print(\"Test counts :\", compute_class_counts(test_imgs))\n",
    "\n",
    "# Vérif rapide: au moins 1 image par classe\n",
    "for c in cfg.class_names:\n",
    "    assert len(train_imgs[c]) > 0, f\"Aucune image train pour {c}\"\n",
    "    assert len(test_imgs[c]) > 0, f\"Aucune image test pour {c}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a559126",
   "metadata": {},
   "source": [
    "## TEST Petit sample -> Patient P_00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25de547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(images_by_class, class_names, n_per_class: int, image_size):\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    skipped = 0\n",
    "\n",
    "    for idx, c in enumerate(class_names):\n",
    "        paths = images_by_class[c][:n_per_class]\n",
    "        for p in paths:\n",
    "            try:\n",
    "                img = load_image_cv2(p, image_size)\n",
    "            except Exception as e:\n",
    "                skipped += 1\n",
    "                # Log minimal\n",
    "                print(f\"Skip: {p} ({type(e).__name__})\")\n",
    "                continue\n",
    "\n",
    "            img = normalize_0_1(img)\n",
    "            feat = make_sklearn_features(img)  # flatten\n",
    "            X_list.append(feat)\n",
    "            y_list.append(idx)\n",
    "\n",
    "    if len(X_list) == 0:\n",
    "        raise RuntimeError(\"Aucune image n'a pu être chargée (tout a été skip).\")\n",
    "\n",
    "    X = np.stack(X_list, axis=0)\n",
    "    y = np.array(y_list, dtype=np.int64)\n",
    "    print(f\"Dataset construit: {len(y)} samples, skipped={skipped}\")\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X_train, y_train = build_dataset(train_imgs, cfg.class_names, n_per_class=200, image_size=cfg.image_size)\n",
    "X_test, y_test   = build_dataset(test_imgs, cfg.class_names, n_per_class=80,  image_size=cfg.image_size)\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_test :\", X_test.shape,  \"y_test :\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569be371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split calibration\n",
    "X_fit, X_cal, y_fit, y_cal = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "res = train_logistic_regression(X_fit, y_fit, max_iter=2000)\n",
    "base_model = res.model\n",
    "\n",
    "# Calibration (isotonic ou sigmoid)\n",
    "calibrated = calibrate_sklearn_classifier(base_model, X_cal, y_cal, method=\"isotonic\")\n",
    "\n",
    "# Eval rapide\n",
    "proba_test = calibrated.predict_proba(X_test)\n",
    "y_pred = proba_test.argmax(axis=1)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test accuracy (calibrated):\", round(acc, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af821a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prendre un exemple dans le test (ici le 1er \"notumor\" si dispo, sinon le 1er tout court)\n",
    "target_class = \"notumor\"\n",
    "sample_path = test_imgs[target_class][0] if len(test_imgs[target_class]) > 0 else list(test_imgs.values())[0][0]\n",
    "\n",
    "img = load_image_cv2(sample_path, cfg.image_size)\n",
    "img = normalize_0_1(img)\n",
    "feat = make_sklearn_features(img).reshape(1, -1)\n",
    "\n",
    "proba = calibrated.predict_proba(feat)[0]\n",
    "\n",
    "scores_by_class = {cfg.class_names[i]: float(proba[i]) for i in range(len(cfg.class_names))}\n",
    "thresholds = DecisionThresholds()\n",
    "decision = generer_recommandation(scores_by_class, thresholds)\n",
    "\n",
    "print(\"Sample:\", sample_path.name)\n",
    "print(\"Scores:\", {k: round(v, 4) for k, v in scores_by_class.items()})\n",
    "print(\"Decision:\", decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3ebec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id = \"P_00001\"\n",
    "report = creer_rapport_decision(\n",
    "    patient_id=patient_id,\n",
    "    scores_by_class=scores_by_class,\n",
    "    decision=decision,\n",
    ")\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c25ae18",
   "metadata": {},
   "source": [
    "## 3. Baselines : Régression Logistique calibrée\n",
    "### 3.1 Extraction de features (baseline)\n",
    "- Approche simple (ex: flatten / features classiques)\n",
    "### 3.2 Entraînement RegLog multinomiale\n",
    "### 3.3 Calibration (Platt ou Isotonic)\n",
    "### 3.4 Analyse des scores\n",
    "- Distribution max_prob\n",
    "- Cas incertains (max_prob < 0.7)\n",
    "\n",
    "## 4. MLP probabiliste et limites\n",
    "### 4.1 Préparation des features pour MLP\n",
    "### 4.2 Entraînement MLP\n",
    "### 4.3 Analyse confiance / erreurs\n",
    "- Où le modèle se trompe\n",
    "- Tranches de confiance\n",
    "\n",
    "## 5. CNN calibré pour la décision\n",
    "### 5.1 Dataloaders image (tensor)\n",
    "### 5.2 Architecture CNN\n",
    "### 5.3 Entraînement\n",
    "### 5.4 Temperature Scaling (calibration)\n",
    "### 5.5 Sauvegarde d’activations (pour analyse)\n",
    "\n",
    "## 6. Moteur de décision clinique (règles & seuils)\n",
    "- Implémentation des seuils\n",
    "- Gestion asymétrique des faux négatifs (notumor < 0.95)\n",
    "\n",
    "## 7. Tableau de bord : génération de rapports\n",
    "- Générer des rapports textuels pour 20 patients (échantillon)\n",
    "- Afficher quelques rapports dans le notebook\n",
    "\n",
    "## 8. Analyse de performance orientée \"métier\"\n",
    "### 8.1 Couverture automatique\n",
    "### 8.2 Accuracy par tranche de confiance\n",
    "- Vérifier accuracy > 95% quand confiance > 0.85\n",
    "### 8.3 Analyse coût-bénéfice\n",
    "- Coût = (FN*1000) + (FP*100) + (Revision*50)\n",
    "\n",
    "## 9. Incertitude (MC Dropout)\n",
    "- Estimation sur quelques images\n",
    "- Comparaison avec confiance softmax\n",
    "\n",
    "## 10. Analyse critique et éthique\n",
    "- Limites, risques, faux négatifs\n",
    "- Place du radiologue, biais de données\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
